set.seed(123)
m2 <- tuneRF(
x          = ames_train[features],
y          = ames_train$Sale_Price,
ntreeTry   = 500,
mtryStart  = 5,
stepFactor = 1.5,
improve    = 0.01,
trace      = FALSE      # to not show real-time progress
)
system.time(
ames_randomForest <- randomForest(
formula = Sale_Price ~ .,
data    = ames_train,
ntree   = 500,
mtry    = floor(length(features) / 3)
)
system.time(
system.time(
ames_ranger <- ranger(
formula   = Sale_Price ~ .,
data      = ames_train,
num.trees = 500,
mtry      = floor(length(features) / 3)
)
)
hyper_grid <- expand.grid(
mtry       = seq(20, 30, by = 2),
node_size  = seq(3, 9, by = 2),
sampe_size = c(.55, .632, .70, .80),
OOB_RMSE   = 0
)
nrow(hyper_grid)
for(i in 1:nrow(hyper_grid)) {
model <- ranger(
formula         = Sale_Price ~ .,
data            = ames_train,
num.trees       = 500,
mtry            = hyper_grid$mtry[i],
min.node.size   = hyper_grid$node_size[i],
sample.fraction = hyper_grid$sampe_size[i],
seed            = 123
)
hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}
hyper_grid %>%
dplyr::arrange(OOB_RMSE) %>%
head(10)
OOB_RMSE <- vector(mode = "numeric", length = 100)
for(i in seq_along(OOB_RMSE)) {
optimal_ranger <- ranger(
formula         = Sale_Price ~ .,
data            = ames_train,
num.trees       = 500,
mtry            = 28,
min.node.size   = 3,
sample.fraction = .8,
importance      = 'impurity'
)
OOB_RMSE[i] <- sqrt(optimal_ranger$prediction.error)
}
hist(OOB_RMSE, breaks = 20)
plot(optimal_ranger$variable.importance)
p1 <- vip::vip(optimal_ranger, num_features = 25, bar = FALSE)
gridExtra::grid.arrange(p1, nrow = 1)
which.max(optimal_ranger$variable.importance)
which.min(optimal_ranger$variable.importance)
library(sp)
data(meuse)
str(meuse)
?meuse
meuse$logZn <- log10(meuse$zinc)
hist(meuse$logZn); rug(meuse$logZn)
library(ranger)
set.seed(314)
m.lzn.ra <- ranger(logZn ~ ffreq + x + y + dist.m + elev + soil + lime,
data = meuse,
importance = "permutation",
scale.permutation.importance = TRUE,
mtry = 3)
print(m.lzn.ra)
set.seed(314)
m.lzn.ra.i <- ranger(logZn ~ ffreq + x + y + dist.m + elev + soil + lime,
data = meuse,
importance = 'impurity',
mtry = 3)
print(m.lzn.ra.i)
p.ra <- predict(m.lzn.ra, data=meuse)
str(p.ra)
summary(r.rap <- meuse$logZn - p.ra$predictions)
(rmse.ra <- sqrt(sum(r.rap^2)/length(r.rap)))
plot(meuse$logZn ~ p.ra$predictions, asp=1, pch=20, xlab="fitted", ylab="actual", xlim=c(2,3.3),          ylim=c(2,3.3), main="log10(Zn), Meuse topsoils, Ranger")
grid(); abline(0,1)
summary(m.lzn.ra$predictions)
summary(p.rf.oob)
ranger has slightly lower OOB predictions than randomForest.
abline(0,1); grid()
plot(meuse$logZn ~ m.lzn.ra$predictions, asp=1, pch=20,
ylab="actual", xlab="OOB X-validation estimates",
xlim=c(2,3.3), ylim=c(2,3.3),
main="ranger")
abline(0,1); grid()
ranger = ranger::importance(m.lzn.ra)
ranger
ranger =ranger::importance(m.lzn.ra.i)
ranger
#-------------------------------------------------------------------------------
require(vip)
v1 <- vip(m.lzn.ra, title = "Ranger Permutation")
v2 <- vip(m.lzn.ra.i, title = "Ranger Impurity")
grid.arrange(v1, v2, ncol = 2)
n <- 48
ra.stats <- data.frame(rep=1:10, rsq=as.numeric(NA), mse=as.numeric(NA))
system.time(
for (i in 1:n) {
model.ra <- ranger(logZn ~ ffreq + x + y + dist.m + elev + soil + lime,
data=meuse, importance="none", mtry=5,
write.forest = FALSE)
ra.stats[i, "mse"] <- model.ra$prediction.error
ra.stats[i, "rsq"] <- model.ra$r.squared
}
)
summary(ra.stats[,2:3])
hist(ra.stats[,"rsq"], xlab="ranger R^2", breaks = 16, main = "Frequency of fits (R^2)")
rug(ra.stats[,"rsq"])
hist(ra.stats[,"mse"], xlab="ranger RMSE", breaks = 16, main = "Frequency of OOB accuracy (RMSE)")
rug(ra.stats[,"mse"])
#--------------------------- Title ---------------------------------------------
## Project: ML_R_Project.Rproj
## Script:  G_Silge_Tune_RF_TidyTues.R
## Programmer: Christopher Griffin
## Creation Date: 4/28/23
## Edit Date:  4/28/23
## Notes: This follows the tutorial Tune random forests for #TidyTuesday IKEA prices
## by Julia Silge. https://juliasilge.com/blog/ikea-prices/
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
## Explore the data
#-------------------------------------------------------------------------------
# Our modeling goal is to predict the price of IKEA furniture from other furniture
# characteristics like category and size. Let’s start by reading in the data.
library(tidyverse)
ikea <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-11-03/ikea.csv")
# Rename one of the columns since it's funky.
names(ikea)[names(ikea) == "...1"] <- "X1"
# How is the price related to the furniture dimensions?
ikea %>%
select(X1, price, depth:width) %>%
pivot_longer(depth:width, names_to = "dim") %>%
ggplot(aes(value, price, color = dim)) +
geom_point(alpha = 0.4, show.legend = FALSE) +
scale_y_log10() +
facet_wrap(~dim, scales = "free_x") +
labs(x = NULL)
# Let’s do a bit of data preparation for modeling. There are still lots of NA values for furniture dimensions but we are going to impute those.
ikea_df <- ikea %>%
select(price, name, category, depth, height, width) %>%
mutate(price = log10(price)) %>%
mutate_if(is.character, factor)
ikea_df
#-------------------------------------------------------------------------------
## Build a model
#-------------------------------------------------------------------------------
# We can start by loading the tidymodels metapackage, splitting our data into training and testing sets, and creating resamples.
library(tidymodels)
set.seed(123)
ikea_split <- initial_split(ikea_df, strata = price)
ikea_train <- training(ikea_split)
ikea_test  <- testing(ikea_split)
set.seed(234)
ikea_folds <- bootstraps(ikea_train, strata = price)
ikea_folds
# In this analysis, we are using a function from usemodels to provide scaffolding for getting started with tidymodels tuning. The two inputs we need are:
#
#   a formula to describe our model price ~ .
#   our training data ikea_train
# install.packages("usemodels")
library(usemodels)
use_ranger(price ~., data = ikea_train)
# The output that we get from the usemodels scaffolding sets us up for random forest tuning, and we can add just a few more feature engineering steps to
# take care of the numerous factor levels in the furniture name and category, “cleaning” the factor levels, and imputing the missing data in the furniture
# dimensions. Then it’s time to tune!
# install.packages("textrecipes")
# install.packages("doParallel")
# install.packages("janitor") # needed for step_clean
library(textrecipes)
ranger_recipe <-
recipe(formula = price ~ ., data = ikea_train) %>%
step_other(name, category, threshold = 0.01) %>%
step_clean_levels(name, category) %>%
step_impute_knn(depth, height, width)
ranger_spec <-
rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
set_mode("regression") %>%
set_engine("ranger")
ranger_workflow <-
workflow() %>%
add_recipe(ranger_recipe) %>%
add_model(ranger_spec)
set.seed(8577)
doParallel::registerDoParallel()
ranger_tune <-
tune_grid(ranger_workflow,
resample = ikea_folds,
grid = 11
)
# The usemodels output required us to decide for ourselves on the resamples and grid
# to use; it provides sensible defaults for many options based on our data but we
# still need to use good judgment for some modeling inputs.
#-------------------------------------------------------------------------------
## Explore results
#-------------------------------------------------------------------------------
# Now let’s see how we did. We can check out the best-performing models in the tuning results.
show_best(ranger_tune, metric = "rmse")
show_best(ranger_tune, metric = "rsq")
# How did all the possible parameter combinations do?
autoplot(ranger_tune)
# We can finalize our random forest workflow with the best performing parameters.
final_rf <- ranger_workflow %>%
finalize_workflow(select_best(ranger_tune))
final_rf
# The function last_fit() fits this finalized random forest one last time to the training data and evaluates one last time on the testing data.
ikea_fit <- last_fit(final_rf, ikea_split)
ikea_fit
# The metrics in ikea_fit are computed using the testing data.
collect_metrics(ikea_fit)
# The predictions in ikea_fit are also for the testing data.
collect_predictions(ikea_fit) %>%
ggplot(aes(price, .pred)) +
geom_abline(lty = 2, color = "gray50") +
geom_point(alpha = 0.3, color = "red") +
coord_fixed()
# We can use the trained workflow from ikea_fit for prediction, or save it to use later.
predict(ikea_fit$.workflow[[1]], ikea_test[15, ])
# Lastly, let’s learn about feature importance for this model using the vip package.
# For a ranger model, we do need to go back to the model specification itself and update
# the engine with importance = "permutation" in order to compute feature importance.
# This means fitting the model one more time.
library(vip)
imp_spec <- ranger_spec %>%
finalize_model(select_best(ranger_tune)) %>%
set_engine("ranger", importance = "permutation")
workflow() %>%
add_recipe(ranger_recipe) %>%
add_model(imp_spec) %>%
fit(ikea_train) %>%
pull_workflow_fit() %>%
vip(aesthetics = list(alpha = 0.8, fill = "midnightblue"))
workflow() %>%
add_recipe(ranger_recipe) %>%
add_model(imp_spec) %>%
fit(ikea_train) %>%
extract_fit_parsnip() %>%
vip(aesthetics = list(alpha = 0.8, fill = "midnightblue"))
library(tidyverse)
sf_trees <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-28/sf_trees.csv")
View(sf_trees)
trees_df <- sf_trees %>%
mutate(
legal_status = case_when(
legal_status == "DPW Maintained" ~ legal_status,
TRUE ~ "Other"
),
plot_size = parse_number(plot_size)
) %>%
select(-address) %>%
na.omit() %>%
mutate_if(is.character, factor)
View(trees_df)
trees_df %>%
ggplot(aes(longitude, latitude, color = legal_status)) +
geom_point(size = 0.5, alpha = 0.4) +
labs(color = NULL)
trees_df %>%
count(legal_status, caretaker) %>%
add_count(caretaker, wt = n, name = "caretaker_count") %>%
filter(caretaker_count > 50) %>%
group_by(legal_status) %>%
mutate(percent_legal = n / sum(n)) %>%
ggplot(aes(percent_legal, caretaker, fill = legal_status)) +
geom_col(position = "dodge") +
labs(
fill = NULL,
x = "% of trees in each category"
)
View(trees_df)
library(tidymodels)
set.seed(123)
trees_split <- initial_split(trees_df, strata = legal_status)
trees_train <- training(trees_split)
trees_test  <- testing(trees_split)
View(trees_split)
tree_prep <- prep(tree_rec)
tree_rec <- recipe(legal_status ~ ., data = trees_train) %>%
update_role(tree_id, new_role = "ID") %>%
step_other(species, caretaker, threshold = 0.01) %>%
step_other(site_info, threshold = 0.005) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_date(date, features = c("year")) %>%
step_rm(date) %>%
step_downsample(legal_status)
library(tidymodels)
library(recipes)
set.seed(123)
trees_split <- initial_split(trees_df, strata = legal_status)
trees_train <- training(trees_split)
trees_test  <- testing(trees_split)
# Next we build a recipe for data preprocessing.
# First, we must tell the recipe() what our model is going to be (using a formula here) and what our training data is.
# Next, we update the role for tree_id, since this is a variable we might like to keep around for convenience as an
# identifier for rows but is not a predictor or outcome.
# Next, we use step_other() to collapse categorical levels for species, caretaker, and the site info. Before this step,
# there were 300+ species!
# The date column with when each tree was planted may be useful for fitting this model, but probably not the exact date,
# given how slowly trees grow. Let’s create a year feature from the date, and then remove the original date variable.
# There are many more DPW maintained trees than not, so let’s downsample the data for training.
# The object tree_rec is a recipe that has not been trained on data yet (for example, which categorical levels should
# be collapsed has not been calculated) and tree_prep is an object that has been trained on data.
tree_rec <- recipe(legal_status ~ ., data = trees_train) %>%
update_role(tree_id, new_role = "ID") %>%
step_other(species, caretaker, threshold = 0.01) %>%
step_other(site_info, threshold = 0.005) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_date(date, features = c("year")) %>%
step_rm(date) %>%
step_downsample(legal_status)
library(themis)
install.packages("themis")
library(themis)
set.seed(123)
trees_split <- initial_split(trees_df, strata = legal_status)
trees_train <- training(trees_split)
trees_test  <- testing(trees_split)
# Next we build a recipe for data preprocessing.
# First, we must tell the recipe() what our model is going to be (using a formula here) and what our training data is.
# Next, we update the role for tree_id, since this is a variable we might like to keep around for convenience as an
# identifier for rows but is not a predictor or outcome.
# Next, we use step_other() to collapse categorical levels for species, caretaker, and the site info. Before this step,
# there were 300+ species!
# The date column with when each tree was planted may be useful for fitting this model, but probably not the exact date,
# given how slowly trees grow. Let’s create a year feature from the date, and then remove the original date variable.
# There are many more DPW maintained trees than not, so let’s downsample the data for training.
# The object tree_rec is a recipe that has not been trained on data yet (for example, which categorical levels should
# be collapsed has not been calculated) and tree_prep is an object that has been trained on data.
tree_rec <- recipe(legal_status ~ ., data = trees_train) %>%
update_role(tree_id, new_role = "ID") %>%
step_other(species, caretaker, threshold = 0.01) %>%
step_other(site_info, threshold = 0.005) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_date(date, features = c("year")) %>%
step_rm(date) %>%
step_downsample(legal_status)
tree_prep <- prep(tree_rec)
juiced    <- juice(tree_prep)
tune_spec <- rand_forest(
mtry = tune(),
trees = 1000,
min_n = tune()
) %>%
set_mode("classification") %>%
set_engine("ranger")
# Finally, let’s put these together in a workflow(), which is a convenience container object for carrying around bits of models.
tune_wf <- workflow() %>%
add_recipe(tree_rec) %>%
add_model(tune_spec)
# Now it’s time to tune the hyperparameters for a random forest model. First, let’s create a set of cross-validation resamples to use for tuning.
set.seed(234)
trees_folds <- vfold_cv(trees_train)
# We can’t learn the right values when training a single model, but we can train a whole bunch of models and see which ones turn out best.
# We can use parallel processing to make this go faster, since the different parts of the grid are independent. Let’s use grid = 20 to choose 20 grid points automatically.
doParallel::registerDoParallel()
set.seed(345)
tune_res <- tune_grid(
tune_wf,
resamples = treefolds,
grid = 20
)
set.seed(234)
trees_folds <- vfold_cv(trees_train)
# We can’t learn the right values when training a single model, but we can train a whole bunch of models and see which ones turn out best.
# We can use parallel processing to make this go faster, since the different parts of the grid are independent. Let’s use grid = 20 to choose 20 grid points automatically.
doParallel::registerDoParallel()
set.seed(345)
tune_res <- tune_grid(
tune_wf,
resamples = tree_folds,
grid = 20
)
set.seed(234)
trees_folds <- vfold_cv(trees_train)
# We can’t learn the right values when training a single model, but we can train a whole bunch of models and see which ones turn out best.
# We can use parallel processing to make this go faster, since the different parts of the grid are independent. Let’s use grid = 20 to choose 20 grid points automatically.
doParallel::registerDoParallel()
set.seed(345)
tune_res <- tune_grid(
tune_wf,
resamples = trees_folds,
grid = 20
)
tune_res
#--------------------------- Title ---------------------------------------------
## Project: ML_R_Proejct.Rproj
## Script:  J_Silge_Adv_Tuning_RF.R
## Programmer: Christopher Griffin
## Creation Date: 4/28/23
## Edit Date:  4/28/23
## Notes: This follows the tutorial Tuning random forest hyperparameters with #TidyTuesday trees data
## by J Silge https://juliasilge.com/blog/sf-trees-random-tuning/
#-------------------------------------------------------------------------------
#-------------------------------------------------------------------------------
## Explore the data
#-------------------------------------------------------------------------------
# Our modeling goal here is to predict the legal status of the trees in San Francisco in the #TidyTuesday dataset
# using a random forest model.
# Let’s build a model to predict which trees are maintained by the San Francisco Department of Public Works and
# which are not. We can use parse_number() to get a rough estimate of the size of the plot from the plot_size
# column. Instead of trying any imputation, we will just keep observations with no NA values.
library(tidyverse)
sf_trees <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-28/sf_trees.csv")
trees_df <- sf_trees %>%
mutate(
legal_status = case_when(
legal_status == "DPW Maintained" ~ legal_status,
TRUE ~ "Other"
),
plot_size = parse_number(plot_size)
) %>%
select(-address) %>%
na.omit() %>%
mutate_if(is.character, factor)
# Let’s do a little exploratory data analysis before we fit models. How are these trees distributed across San Francisco?
trees_df %>%
ggplot(aes(longitude, latitude, color = legal_status)) +
geom_point(size = 0.5, alpha = 0.4) +
labs(color = NULL)
# You can see streets! And there are definitely spatial differences by category.
# What relationships do we see with the caretaker of each tree?
trees_df %>%
count(legal_status, caretaker) %>%
add_count(caretaker, wt = n, name = "caretaker_count") %>%
filter(caretaker_count > 50) %>%
group_by(legal_status) %>%
mutate(percent_legal = n / sum(n)) %>%
ggplot(aes(percent_legal, caretaker, fill = legal_status)) +
geom_col(position = "dodge") +
labs(
fill = NULL,
x = "% of trees in each category"
)
#-------------------------------------------------------------------------------
## Build model
#-------------------------------------------------------------------------------
# We can start by loading the tidymodels metapackage, and splitting our data into training and testing sets.
library(tidymodels)
library(recipes)
# install.packages("themis")
library(themis)
set.seed(123)
trees_split <- initial_split(trees_df, strata = legal_status)
trees_train <- training(trees_split)
trees_test  <- testing(trees_split)
# Next we build a recipe for data preprocessing.
# First, we must tell the recipe() what our model is going to be (using a formula here) and what our training data is.
# Next, we update the role for tree_id, since this is a variable we might like to keep around for convenience as an
# identifier for rows but is not a predictor or outcome.
# Next, we use step_other() to collapse categorical levels for species, caretaker, and the site info. Before this step,
# there were 300+ species!
# The date column with when each tree was planted may be useful for fitting this model, but probably not the exact date,
# given how slowly trees grow. Let’s create a year feature from the date, and then remove the original date variable.
# There are many more DPW maintained trees than not, so let’s downsample the data for training.
# The object tree_rec is a recipe that has not been trained on data yet (for example, which categorical levels should
# be collapsed has not been calculated) and tree_prep is an object that has been trained on data.
tree_rec <- recipe(legal_status ~ ., data = trees_train) %>%
update_role(tree_id, new_role = "ID") %>%
step_other(species, caretaker, threshold = 0.01) %>%
step_other(site_info, threshold = 0.005) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_date(date, features = c("year")) %>%
step_rm(date) %>%
step_downsample(legal_status)
tree_prep <- prep(tree_rec)
juiced    <- juice(tree_prep)
# Now it’s time to create a model specification for a random forest where we will tune mtry (the number of predictors to
# sample at each split) and min_n (the number of observations needed to keep splitting nodes). These are hyperparameters
# that can’t be learned from data when training the model.
tune_spec <- rand_forest(
mtry = tune(),
trees = 1000,
min_n = tune()
) %>%
set_mode("classification") %>%
set_engine("ranger")
# Finally, let’s put these together in a workflow(), which is a convenience container object for carrying around bits of models.
tune_wf <- workflow() %>%
add_recipe(tree_rec) %>%
add_model(tune_spec)
# This workflow is ready to go.
#-------------------------------------------------------------------------------
## Train hyperparameters
#-------------------------------------------------------------------------------
# Now it’s time to tune the hyperparameters for a random forest model. First, let’s create a set of cross-validation resamples to use for tuning.
set.seed(234)
trees_folds <- vfold_cv(trees_train)
# We can’t learn the right values when training a single model, but we can train a whole bunch of models and see which ones turn out best.
# We can use parallel processing to make this go faster, since the different parts of the grid are independent. Let’s use grid = 20 to choose 20 grid points automatically.
doParallel::registerDoParallel()
set.seed(345)
tune_res <- tune_grid(
tune_wf,
resamples = trees_folds,
grid = 20
)
